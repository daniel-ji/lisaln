#!/bin/sh
#Save all scripts to ~/database/pipeline_script
# Script template is ./template 

dotime=1;starts=`date +%s` ; starttime=`date`

thisfile=$0
doout=0
col=1
head=0
urlbase='http://pfam.xfam.org/protein/'
max_try=5  #max try to access url 
format=`echo -e "UniProtID\tDomain1\t..."`

debug=0
start=1
ends=26
force1=0  #force to get oncogenes in step 1
force2=0  #force to get UniprotID in step 2.  =0: bypass step2 =1:redo step2 =2: Only redo genes that has no UniProtID in previous result
force3=0
force4=0
pdb='NA'
map=1
model=0
modelfolder='./'
fill=0;fills=''
dup=0

oldline=$*   #all argvs
#echo $0 $oldline
if [ -n "$1" ] ; then
 aaa=`echo "$1" | awk '{print substr($1,1,1)}'`  #check if first input is -XXX
 while [ $aaa == "-" ] ; do
  case $1 in
   -out)output=$2;doout=1;shift 2;;
   -col)col=$2;shift 2;;
   -head)head=1;shift;;
   -keepdup)dup=1;shift;;

   *) $0; echo "***Fatal error @ $0! Argument $1 is unrecoginized and ignored : $0 $oldline!" 1>&2 ; exit;;
  esac
  [ -n "$1" ] && aaa=`echo "$1" | awk '{print substr($1,1,1)}'` || aaa='NA'
 done
fi
echo $i

if [ -n "$1" ] ; then
 input=$1
else
cat << ttt

 Get PFam domains based on UniProt ID from Pfam website $urlbase

How to use SMART and Pfam domain database to find all sequences for a domain and do sequence aligment?
      Ref: nature reviews:genetics 2006. vol7 715
 1. If do not know domain name/ID, search PDB id in Pfam database: http://pfam.xfam.org/   For example: JMJD1B PDB as 4c8d
 2. In return page of 4c8d, click "Domain organisation". Then  click on Jmjc domain
 3. In Jmjc domain page (Family: JmjC (PF02373)), shows 305 structures, 6374 sequences in 248 architectures
 4 Click on Trees to show phylogenetic tree
 5. Click on 305 structures to see all PDBs
 6. Click on 248 archtectures to see all domain-chains that contain jmjc-domain
      For each archtecture, click on "Show all sequences with this architecture" to see human ones
    Best to view architecture in SAMRT database: http://smart.embl-heidelberg.de
     Click "Normal" in SMART homepage
     Search "Domain Selection" for jmjc
      Then 'Expand all nodes' to search 'homo sapiens' 97 architectures: check all humans
      In 'Action selection' can download 97 human sequences. Or 'display the domain architecture'
        Click 'Display proteins'


 Usage: [Options] $0 UniprotID or List
  List: a list of UniprotID at col $col w/ header or not
  
 Options:
  -out Output : User defined output name. Format as $format
  -col ColNum : When input is List, UniprotID col number. [$col]
  -keepdup : Do NOT remove duplicate names. Default: duplicate names will be removed
  -head : When input is List, the first row is header to discard
    If UniProt ID is from ./offtarget_pipe or ./offtarget_pipe_many output, it will check where is col named as UniProtID
  
 Example: 
   $0 P18428
     #get PFam domains for UniProtID P18428
   $0 -col 2 -head 1 List.txt
     #input is List w/ header and UniProtID in col 2
   $0 -head offtarget_pipe.output 
     #When Input is from ./offtarget_pipe, no need to say UniProtID col. It will check automatically which col has UniProtID keyword


  NOTE: Convert UniProt /PDB /GeneID : http://biodb.jp/index.cgi?lang=&tax
        Search PDB by UniProt ID: PDB | Advanced Search | UniProtKB Access Number
  NOTE: To download homology models for UniProt ID that does not have PDB, run ./pdb_model_download
  NOTE: To Get protein Function, ProteinNames, shortProteinNames, GeneNames, run ./UniProt_getProperty
  NOTE: To find domains from NCBI CCD: ./NCBI_blast -ccd protein.fasta
  NOTE: Can also run ./domain_cluster to get Pfam/SMART/InterPro domains
  NOTE: To cluster proteins by Pathway/Function/Domain/Seqidentity/Structure, run ./protein_cluster

  NOTE: May also extract domain region. But so far not yet

 NOTE: from 2019/1, the format of download changed and need modify this script: See Nuclease/
   wget http://pfam.xfam.org/protein/Q17RS7 -t 1 -O i
   ./html_strip -remove ";" -space -removejunk i > j
   Compare GEN1 with http://pfam.xfam.org/protein/Q17RS7

ttt
  exit
fi

temp=$0'_'$$'.tmp';  temp2=$temp'2' ; temp3=$temp'3' ; temp4=$temp'4'; temp5=$temp'5'; temp6=$temp'6'; temp7=$temp'7'

momdir=`dirname $urlbase`
#Check root folder: scalemp1=p-gpu1; p-ngs=hpc
ed='/home/holi/database/pipeline_script/'
drd='/home/holi/database/pipeline_script/'; [ -d $drd ] && ed=$drd  #My old computer
drd='/isi-dcnl/flower_data/hongzhi/database/pipeline_script/'; [ -d $drd ] && ed=$drd #holi@p-ngs2
drd='/isi-flower/flower_data/hongzhili/database/pipeline_script/'; [ -d $drd ] && ed=$drd #holi@p-gpu1
drd='/net/isi-dcnl/ifs/user_data/hongzhi/database/pipeline_script/'; [ -d $drd ] && ed=$drd ##holi@hpc-access1.coh.org
drd='/flower_data/hongzhili/database/pipeline_script/'; [ -d $drd ] && ed=$drd #holi@scalemp1
drd='/home/holi/database/pipeline_script/'; [ -d $drd ] && ed=$drd  #My newest computer

thisfolder=`pwd`; thisfolder=$thisfolder'/'
if [ $thisfolder != $ed ] ; then
 cp -f $ed/back $ed/get $ed/alphabet_number $ed/html_strip $ed/lists_remove_duplicate $ed/CSV_getCol $ed/list_mergeTwo $ed/pdb_seq_align_PISCES .
 cp -f $ed/pdb_model_download $ed/NCBI_blast .
fi

[ $doout -ne 1 ] && output=$temp.out

if [ -s $input ] ; then
 echo "Input is List file w/ UniProtID in col $col"
 if [ $head -eq 1 ] ; then
  scol=`head -1 $input | awk '{s=0;for(i=1;i<=NF;i++){if($i=="UniProtID"){s=i}};print s}'`
  if [ $scol -gt 0 ] ; then
   col=$scol 
   echo " Found UniProtID in col $col"
  fi
 fi
 awk '{s='$col';h='$head';if(NR>h){print $s}}' $input > $temp3
 [ $doout -ne 1 ] && output=$input'_Pfam.xls'
else
 echo $input  > $temp3
fi
nc=`wc -l $temp3 | awk '{print $1}'`

if [ $dup -ne 1 ] ; then
 echo "Remove duplicate names"
 awk '{did=0;for(i=1;i<=n;i++){if($1==a[i]){did=1;break}};if(did==0){n++;a[n]=$1}}END{for(i=1;i<=n;i++){print a[i]}}' $temp3 > $temp2
 mv $temp2 $temp3
 ncu=`wc -l $temp3 | awk '{print $1}'`
 echo " $ncu unique Proteins (total $nc) will be checked and saved in $output"
 nc=$ncu
else
 echo " Total $nc Proteins will be checked and saved in $output" 
fi

start=1;ends=$nc

echo -e $format > $output
for (( i=$start ; i<=$ends ; i++ )) ; do
 ID=`head -$i $temp3 | tail -1 | awk '{print $1}'`
 url=$urlbase$ID
 er=1
 cn=1
 while [ $er -gt 0 ] ; do   #sometimes wget gets ERROR from busy server
  wget $url -t 1 -O $temp >& $temp2   #-t 1  Only try once when failed
  er=`grep "ERROR" $temp2 | wc -l | awk '{print $1}'`
  cn=`awk 'BEGIN{print '$cn'+1}'`
  [ $cn -gt $max_try ] && er=-1
  [ $cn -gt 2 ] && echo Retry $cn times
 done

 #remove <> in html
 ./html_strip -remove ";" -space -removejunk $temp > $temp2    
 #cp $temp2 i

#Get  Pfam domains
#Keyword started row: Pfam domains
#Domain started at: Pfam A
#Pfam A 
#LBP_BPI_CETP
#213 
#28.30
#28.30 
#165.40
#163.90
#1e-45 
#2.8e-45


 cat $temp2 | awk 'BEGIN{s=0;did=0;s2=0;mdid=0;mdid2=0;mdid3=0;did2=0;f="";name="";s3=0;did3=0;sname="";ID="'$ID'"
  gname="";s4=0;did4=0;n=0
 }{

 #Get domain
 if(s==1&&did==1){
  did=0
  domain[n]=$_
 }

 #Get: Pfam A
 if(s==1&&NF==2&&$1=="Pfam"&&$2=="A") {
  n++;did=1
 } 

 #Get: Pfam domains
 if (NF==2&&$1=="Pfam"&&$2=="domains") {
  s=1
 }

}END{
 if(n==0){n=1;domain[1]="N/A"}
 printf("%s",ID)
 for(i=1; i<=n; i++){
  printf("\t%s",domain[i])
 }
 printf("\n")
 #print "haha"; print f; print "haha"; print name; print "haha"; print sname;print "haha"; print gname
}' >> $output

done  #i

grep 'N/A' $output
cat $output

echo -e "=> Output Excel saved in $output Formatted as $format"

rm -f $temp* $temp2 $temp3 $temp4 $temp5 $temp6 $temp7; exit

